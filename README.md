# Transcricao_whisper

Beleza, meu dog! Mandou a braba! Se o Bark t√° dando perrengue demais, a gente foca no que t√° rodando liso: Whisper + Ollama! √â um pipeline brabo por si s√≥!

Aqui est√° o README.md pra sua aplica√ß√£o, formal, estudantil, com uns emojis e destaques pra deixar a parada top, focando no que realmente t√° funfando:

üöÄ Projeto de An√°lise de M√≠dia com IA: Transcri√ß√£o e Sumariza√ß√£o Inteligente
Este projeto implementa um pipeline de processamento de m√≠dia utilizando Intelig√™ncia Artificial para converter conte√∫do de √°udio/v√≠deo em texto e, posteriormente, extrair e sumarizar os pontos mais importantes. √â uma ferramenta eficaz para an√°lise r√°pida de conte√∫do falado.

üéØ Objetivo do Projeto
O principal objetivo √© desenvolver uma aplica√ß√£o capaz de:

Transcrever o conte√∫do de arquivos de √°udio ou v√≠deo (.mp3, .mp4, etc.) utilizando o modelo Whisper da OpenAI. üéôÔ∏è
Extrair os pontos-chave e sumarizar o texto transcrito, empregando um Modelo de Linguagem Grande (LLM) hospedado localmente via Ollama (especificamente o llama3.2:latest). üß†
üõ†Ô∏è Tecnologias Envolvidas
Python 3.11.x: A linguagem de programa√ß√£o principal para o projeto.
OpenAI Whisper: Um modelo de IA para transcri√ß√£o autom√°tica de fala, reconhecido por sua alta precis√£o.
Ollama: Uma plataforma que permite a execu√ß√£o e gest√£o de LLMs diretamente em sua m√°quina, garantindo processamento local e privado.
LangChain: Um framework que facilita a orquestra√ß√£o e a intera√ß√£o com os LLMs.
FFmpeg: Uma ferramenta externa essencial para manipula√ß√£o de arquivos de √°udio e v√≠deo, utilizada pelo Whisper para extrair o √°udio dos v√≠deos.
‚öôÔ∏è Instala√ß√£o e Execu√ß√£o
Para configurar e executar o projeto em seu ambiente, siga os passos cuidadosamente:

1. Prepara√ß√£o do Ambiente Python
Certifique-se de ter o Python 3.11.x instalado em seu sistema. Durante o processo de instala√ß√£o, √© fundamental marcar a op√ß√£o "Add Python to PATH" para garantir que os comandos Python sejam facilmente acess√≠veis pelo terminal.

2. Instala√ß√£o do FFmpeg (Passo Crucial!)
O FFmpeg √© uma depend√™ncia externa vital para que o Whisper possa processar arquivos de m√≠dia como MP4.

Baixe uma build pr√©-compilada para Windows do FFmpeg no site oficial ffmpeg.org/download.html. Recomenda-se procurar por links para Gyan.dev ou BtbN/FFmpeg-Builds e selecionar um arquivo .zip ou .7z que contenha _build no nome (ex: ffmpeg-...-essentials_build.7z).
Ap√≥s o download, extraia o conte√∫do do arquivo para um diret√≥rio seguro e de f√°cil acesso (ex: C:\ffmpeg\).
Adicione o caminho completo da subpasta bin (onde se encontra o ffmpeg.exe) √†s vari√°veis de ambiente Path do seu sistema Windows.
Reinicie o computador ap√≥s adicionar ao PATH para que as altera√ß√µes sejam efetivadas em todo o sistema.
Para confirmar a instala√ß√£o, abra um novo terminal e execute o comando ffmpeg -version. ‚úÖ
3. Configura√ß√£o do Ollama
O Ollama √© a plataforma que permite a execu√ß√£o local dos modelos de linguagem.

Baixe e instale o Ollama do site oficial: ollama.com/download.
Ap√≥s a instala√ß√£o, utilize o terminal para baixar o modelo llama3.2:latest, que ser√° usado para a sumariza√ß√£o:
Bash

ollama pull llama3.2:latest
Verifique se o servi√ßo Ollama est√° ativo e em execu√ß√£o em segundo plano (geralmente indicado por um √≠cone na bandeja do sistema).
4. Configura√ß√£o do Ambiente Python e Depend√™ncias
√â altamente recomend√°vel utilizar um ambiente virtual para este projeto, a fim de isolar suas depend√™ncias e evitar conflitos com outras instala√ß√µes Python.

No terminal, navegue at√© o diret√≥rio raiz do seu projeto.
Crie e ative um ambiente virtual:
Bash

python -m venv venv
.\venv\Scripts\activate  # Para usu√°rios Windows (CMD/PowerShell)
Com o ambiente virtual ativado, instale as bibliotecas Python necess√°rias:
Bash

pip install openai-whisper
pip install langchain langchain-community langchain-core
pip install pydantic==1.10.13 # Vers√£o espec√≠fica para garantir compatibilidade com o LangChain
Nota: Se voc√™ possui uma GPU NVIDIA, para otimizar o desempenho do Whisper, √© aconselh√°vel instalar a vers√£o do PyTorch com suporte a CUDA ap√≥s a configura√ß√£o do CUDA Toolkit e cuDNN.
5. Execu√ß√£o do Script Principal
Posicione seu arquivo de √°udio ou v√≠deo (ex: videoplayback.mp4) no mesmo diret√≥rio do seu script Python (Atividade_7.py).

Aten√ß√£o: Se algum diret√≥rio no caminho do seu arquivo contiver caracteres especiais (como √ß ou √£), √© essencial renome√°-lo para remover esses caracteres (ex: Transcricao_aula7 em vez de Transcri√ß√£o_aula7). Isso evita erros de "arquivo n√£o encontrado" pelo FFmpeg.

Abra o arquivo Atividade_7.py em seu editor de c√≥digo e ajuste a vari√°vel AUDIO_VIDEO_PATH para o caminho exato do seu arquivo de entrada.

Execute o script a partir do terminal (com o ambiente virtual ativado):

Bash

python Atividade_7.py
Dica para Exibi√ß√£o de Caracteres Especiais: Se caracteres como √ß ou √£ aparecerem corrompidos na sa√≠da do seu terminal, execute chcp 65001 (no CMD) ou $OutputEncoding = [System.Text.Encoding]::UTF8; chcp 65001 (no PowerShell) antes de executar o script. üí°

‚ö†Ô∏è Observa√ß√£o Importante: Modelos e Espa√ßo em Disco
Este projeto utiliza modelos de IA que requerem um volume consider√°vel de armazenamento em disco.

O modelo Whisper "small" (configurado no c√≥digo para otimiza√ß√£o) ocupa aproximadamente 461 MB de espa√ßo.
O modelo Ollama llama3.2:latest (para sumariza√ß√£o) ocupa cerca de 2.0 GB.
Certifique-se de que seu Disco Local C: (ou o disco onde o cache dos modelos est√° configurado via vari√°veis de ambiente como XDG_CACHE_HOME) possui espa√ßo livre suficiente para o download e a descompress√£o desses modelos. A falta de espa√ßo pode causar erros de "No space left on device", impedindo a execu√ß√£o do projeto. üíæ

